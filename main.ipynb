{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Utility\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "data = pd.read_csv(r\"C:\\Semester 4\\PP\\NLP_Sentimen\\datasentimen\\training.1600000.processed.noemoticon.csv\",encoding='latin', names = ['polarity','id','date','query','user','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity          id                          date     query  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...           ...         ...                           ...       ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Required NLTK stopword, Lematizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.download('stopwords')\n",
    "stopword = set(stopwords.words('english'))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'am', 'under', 'until', 'so', 'into', 'further', 'from', 'she', 't', 'very', 'by', 'at', \"you'd\", 'themselves', 'where', 'but', 'more', \"you're\", 'those', 'own', 'on', 'then', 'needn', \"shouldn't\", 'because', \"weren't\", 'her', 'had', 'wasn', 'some', 'than', 'theirs', 'have', 'doing', 'for', 'against', 'after', \"isn't\", \"she's\", \"you've\", 'its', 'should', 'will', 'his', 'over', 'd', \"aren't\", 'was', 'itself', \"don't\", 'our', 'few', 'with', 'having', 'shan', 'were', 'both', 'them', \"should've\", 'that', 've', 'through', 'hers', 'no', 'we', 'while', 's', 'why', 'are', 'can', 'you', 'been', 'it', \"won't\", 'again', 'the', 'what', 'such', 'does', \"hadn't\", 'between', 'down', \"couldn't\", 'any', \"it's\", 'do', 'each', 'herself', 'here', 'whom', \"that'll\", 'ain', 'and', \"didn't\", 'not', 'off', 'your', 'weren', 'o', 'below', 'i', 'this', 're', 'has', 'me', 'these', 'about', 'hasn', 'as', 'my', 'how', 'wouldn', 'during', 'yourselves', 'up', 'their', \"wasn't\", 'when', 'same', 'he', 'shouldn', 'or', 'won', 'did', 'haven', 'll', \"you'll\", 'only', 'now', 'if', 'being', 'y', \"hasn't\", \"shan't\", 'out', \"mustn't\", 'myself', 'most', 'which', 'himself', 'didn', 'him', 'don', \"haven't\", 'there', \"doesn't\", 'yours', 'all', 'once', 'be', 'in', 'they', 'couldn', 'ours', 'doesn', 'mightn', 'too', 'ma', \"wouldn't\", \"needn't\", 'who', \"mightn't\", 'mustn', 'nor', 'above', 'm', 'to', 'isn', 'a', 'aren', 'hadn', 'other', 'ourselves', 'just', 'an', 'yourself', 'is', 'before'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krisn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopword = set(stopwords.words('english'))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krisn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krisn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the data is:         1600000\n",
      "No. of positve tagged sentences is:  800000\n",
      "No. of negative tagged sentences is: 800000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data['polarity'] = data['polarity'].replace(4,1)\n",
    "\n",
    "positives = data['polarity'][data.polarity == 1 ]\n",
    "negatives = data['polarity'][data.polarity == 0 ]\n",
    "\n",
    "print('Total length of the data is:         {}'.format(data.shape[0]))\n",
    "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\n",
    "    tweet = re.sub(url_pattern, '', tweet)\n",
    "\n",
    "    # Remove username\n",
    "    username_pattern = r'@[a-zA-Z0-9_]+'\n",
    "    tweet = re.sub(username_pattern, '', tweet)\n",
    "\n",
    "    tweet = tweet.split()\n",
    "    # Remove punctuations\n",
    "    tokens_without_punctuation = [token for token in tweet if token not in string.punctuation]\n",
    "\n",
    "    # Reconstruct the text without the username\n",
    "    tweet = ' '.join(tokens_without_punctuation)\n",
    "\n",
    "    # Tokenize words\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "\n",
    "    # Removing Stop Words\n",
    "    final_tokens = [w for w in tokens if w not in stopword]\n",
    "\n",
    "    # Reduce words to their word stems\n",
    "    word_lemmatizer = WordNetLemmatizer()\n",
    "    final_words = [word_lemmatizer.lemmatize(w) for w in final_tokens if len(w) > 1]\n",
    "\n",
    "    return ' '.join(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "data['processed_tweets'] = data['text'].apply(lambda x: process_tweets(x))\n",
    "print('Text Preprocessing complete.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['processed_tweets']\n",
    "y = data['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.793472</td>\n",
       "      <td>0.788493</td>\n",
       "      <td>0.796177</td>\n",
       "      <td>0.792316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Accuracy    Recall  Precision        F1\n",
       "0  Logistic Regression  0.793472  0.788493   0.796177  0.792316"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "init_models = {\n",
    "    'Logistic Regression': LogisticRegression()\n",
    "}\n",
    "\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "models_names = []\n",
    "\n",
    "for key, model in init_models.items():\n",
    "    models_names.append(key)\n",
    "    model.fit(X_train, y_train)  # Fit the model on training data\n",
    "    y_pred = model.predict(X_test)  # Make predictions on test data\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "models_scores = pd.DataFrame({'Model Name': models_names, 'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1})\n",
    "models_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.741931</td>\n",
       "      <td>0.817952</td>\n",
       "      <td>0.709765</td>\n",
       "      <td>0.760028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Accuracy    Recall  Precision        F1\n",
       "0   LightGBM  0.741931  0.817952   0.709765  0.760028"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "init_models = {\n",
    "   \n",
    "    'LightGBM': lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "models_names = []\n",
    "\n",
    "for key, model in init_models.items():\n",
    "    models_names.append(key)\n",
    "    model.fit(X_train, y_train)  \n",
    "    y_pred = model.predict(X_test)  \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "models_scores = pd.DataFrame({'Model Name': models_names, 'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1})\n",
    "models_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.778066</td>\n",
       "      <td>0.826609</td>\n",
       "      <td>0.753232</td>\n",
       "      <td>0.788216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Name  Accuracy    Recall  Precision        F1\n",
       "0  Gaussian Naive Bayes  0.778066  0.826609   0.753232  0.788216"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "init_models = {\n",
    "\n",
    "    'Gaussian Naive Bayes': BernoulliNB()\n",
    " \n",
    "}\n",
    "\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "models_names = []\n",
    "\n",
    "for key, model in init_models.items():\n",
    "    models_names.append(key)\n",
    "    model.fit(X_train, y_train)  # Convert X_train to dense format\n",
    "    y_pred = model.predict(X_test) # Convert X_test to dense format\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "models_scores = pd.DataFrame({'Model Name': models_names, 'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1})\n",
    "models_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.792588</td>\n",
       "      <td>0.787323</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Accuracy    Recall  Precision        F1\n",
       "0  LinearSVC  0.792588  0.787323   0.795453  0.791367"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "init_models = {\n",
    "\n",
    "    'LinearSVC': LinearSVC()\n",
    " \n",
    "}\n",
    "\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "models_names = []\n",
    "\n",
    "for key, model in init_models.items():\n",
    "    models_names.append(key)\n",
    "    model.fit(X_train, y_train)  # Convert X_train to dense format\n",
    "    y_pred = model.predict(X_test) # Convert X_test to dense format\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "models_scores = pd.DataFrame({'Model Name': models_names, 'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1})\n",
    "models_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I absolutely loved the movie. It was fantastic!\",\n",
    "    \"The restaurant had amazing food and excellent service.\",\n",
    "    \"I was deeply disappointed by the book. It did not meet my expectations.\",\n",
    "    \"The customer support was terrible. I had a horrible experience.\",\n",
    "    \"The concert was electrifying. The performers were incredible.\",\n",
    "    \"The product is of poor quality. I regret buying it.\",\n",
    "    \"The vacation was a dream come true. It exceeded all my expectations.\",\n",
    "    \"The company's policies are unfair and unethical.\",\n",
    "    \"The new software update has greatly improved performance. I'm impressed.\",\n",
    "    \"The service at the hotel was subpar. I wouldn't recommend it.\"\n",
    "]\n",
    "preds=[]\n",
    "for i in texts :\n",
    "    text=process_tweets(i)\n",
    "    text=vectorizer.transform([text])\n",
    "    preds.append(model.predict(text))\n",
    "\n",
    "preds= [item[0] for item in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely loved the movie. It was fantastic!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The restaurant had amazing food and excellent ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was deeply disappointed by the book. It did ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The customer support was terrible. I had a hor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The concert was electrifying. The performers w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The product is of poor quality. I regret buyin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The vacation was a dream come true. It exceede...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The company's policies are unfair and unethical.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The new software update has greatly improved p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The service at the hotel was subpar. I wouldn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen prediction\n",
       "0    I absolutely loved the movie. It was fantastic!                    1\n",
       "1  The restaurant had amazing food and excellent ...                    1\n",
       "2  I was deeply disappointed by the book. It did ...                    0\n",
       "3  The customer support was terrible. I had a hor...                    0\n",
       "4  The concert was electrifying. The performers w...                    1\n",
       "5  The product is of poor quality. I regret buyin...                    0\n",
       "6  The vacation was a dream come true. It exceede...                    1\n",
       "7   The company's policies are unfair and unethical.                    0\n",
       "8  The new software update has greatly improved p...                    1\n",
       "9  The service at the hotel was subpar. I wouldn'...                    1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'text': texts,'sentimen prediction' : preds})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
